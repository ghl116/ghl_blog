# Structured Streaming Programming Guide

## 概览

* Structured Streaming是一个可扩展容错的流式处理引擎，基于Spark Sql引擎。你可以以批量计算的方式实现流式计算。Spark Sql引擎会持续不断的运行并且更新最终结果，随着流式数据的不断到达。你可以使用 Dataset/DataFrame API 以Scala, Java, Python or R语言来实现流式数据的汇集，事件窗口，流程批量join等。这个计算是在同一个Spark SQL引擎执行的。最终：系统保证了端到端，精确一次容错的保证，通过检查点和先写日志。总之，Structured Streaming提供了快速，可扩展，容错，端到商，精确一次的流式处理而不需要用户考虑流式处理。

在内部，默认情况下，Structured Streaming查询是使用微批处理引擎来实现的，把数据流做为一系列小批量的作业实现端到端的延迟在100毫秒，而且精确一次容错保证。然而，从Spark2.3开始，我们引入了新的低延迟处理模型“Continuous Processing”，实现了端到端延迟降低到1毫秒以及至少一次的保证。在你的查询中不需要改变Dataset/DataFrame的操作，你可以根据你的应用需求选择模式。

本文，我们打算解释最常用的概念:使用最多的默认微批模型以及后续提到的Continuous Processing模型。

## 编程模型

Structured Streaming的核心思想是把活动的数据流为了一个不断被追加的数据表。这产生了一个新的数据流处理模型，类似于批处理处理模型。你可以把你的流式计算做为标准的静态数据表的批量查询，而且Spark在没有边界的输入表格中运行增长的查询。

## 基本概念

把输入的数据流作为输入的数据表。当数据流有新数据到达时就像数据追加到数据表中。

查询会生成结果表。每一次触发间隔（如1秒），新数据追加到输入表，最终会更新到结果表。只要结果表更新后，我们希望把变化的结果写到外部输出。

输出定义为把结果写到外部存储。输出有不同的模式：

- Complete Mode：完全模式，整个更新后的结果表会写入到外部存储，这取决于存储连接器决定如何写入到整个数据表。
- Append Mode：追加模式，从上次触发后，只有新数据会追加到结果表中写入存储。这适合于结果表中的数据不会再次改变的查询。
- Update Mode：更新模式。从上次触发后，只有在结果表中更新的记录会写入外部存储。

注：Structured Streaming 不会物理化整个数据表。它从流式数据源中读取最新的可用数据，然后递增的处理更新结果，然后丢弃源数据。它只保存与最小内部状态相关的数据来更新结果。

这个模型和许多流式处理引擎是非常不同的。许多流式系统需要用户维护运行汇集的结果，来保证容错和数据的一致性（至少一次，至多一次和精确一次）。在这个模型中，当新数据到达后，Spark会负责更新结果表，因此减轻了用户的负担。例如：我们看一下这个模型如何基于时间事件处理到达的数据。

## 处理事件时间和晚到数据

Event-time 是嵌入在数据中的时间。对于很多应用，你希望操作Event-time 。例如，你希望得到每分钟IOT工具产生事件的数量，那么你需要使用数据产生的时间，而不是spark收到数据的时间。event-time 在这个模型中是非常自然的定义——这个工具中的每个事件在table中是一行数据，event-time 是一列。这允许窗口汇集指定分组类型以及在event-time 列。每个时间窗口就是一组而且每行属于多个窗口/分组。因此，基于事件时间窗口的汇集查询既可以在一个静态数据集中也可以在一个数据流中实现。

此外，这个模型很自然的处理基于事件时间晚到的数据。由于spark可以更新结果表，所以它有完全的控制权来更新旧的聚合当发现晚到的数据，清理旧的聚合结果。从spark2.1之后，我们支持了watermarking水位线，允许用户指定晚到数据的阈值，允许引擎根据来清理旧的状态。

## 容错算法

Structured Streaming的重要目标之一是实现端到端精确一次。为了达到这个目标，我们设计了Structured Streaming源，目标以及执行引擎来可靠跟踪处理的进度，以便于可以处理任何的故障（重启产生或者处理的时候产生）。每个源都假定有offsets(类似kafka offsets或者kinesis 序列编号)来跟踪读取的流的位置。引擎使用检查点以及先写日志来记录offset变化在每次触发数据处理。Sink被设计为幂等来进行重新处理。通过使用可重跑的源和幂等的sink，Structured Streaming保证了在失败的情况下，端到端精确一次的算法。

## 使用DataSets和DataFrame API

自从Spark2.0开始，DataFrames and Datasets被当做静态有边界数据，以及流式的无界数据。类型静态的DataFrames and Datasets，你可以使用sparkSession来创建DataFrames and Datasets对于流式数据源，并进行操作。


## 创建流式DataFrame和流式DataSet

输入的Source:

- File source:读取一个目录下的文件作为数据流。
- kafka Source：从kafka读取数据。和0.10.0版本及以上兼容
- SocketSource（为了测试）
- Rate Source（为了测试）

## 模式推测和流式数据分区

默认情况下，基于文件流的Structured Streaming需要指定schema，而不是依靠spark自动推测。这个限制保证了一致的schema会在流式处理中使用，即使发生故障。

# 流式数据集的操作

你可以为流式数据指定各种操作，如无类型的Sql操作或者强类型的Rdd操作。


## 关于事件时间的时间窗口操作

在Structured Streaming中对于事件时间进行聚合是很简单的，很像分组聚合。在分组聚合中，聚合值在用户指定的分组列中保存。


## 处理晚到数据和水位线

## 关联操作

Structured Streaming支持流式数据集和静态数据集以及其他数据集关联。数据流关联的结果是逐步生成，类似于之前的流式聚集。

##Stream-static Joins

从spark2.0开始Structured Streaming支持流式和静态数据的关联

## Stream-stream Joins

从spark2.3，我们增加了流式关联的支持。两个数据流关联的挑战是，在任何时间点，数据视图都是不完整的，很难在输入之间找到匹配。一个数据流的一行可以匹配未来还未收到的另一个流的数据。因此，对于两个输入流，我们缓存过去所有流状态，我们自动处理晚到或者超时的数据。


###  Inner Joins with optional Watermarking



### 流去重

你可以使用唯一标识来去重数据流中的数据。这和使用唯一标识列来去重静态数据是一样的。查询会保存必要的记录来过滤去重记录。类似聚合agg。

- 有水位线
- 无水位线

## Arbitrary Stateful Operations(任意有状态的操作)

许多案例都需要比聚合保持更有状态的操作。例如，在许多案例中，你不得不从事件流中跟踪会话。为了跟踪这些会话，你不得不保存 任意类型的数据状态，并且执行任意操作。从spark2.2开始，这可以通过mapGroupsWithState以及flatMapGroupsWithState来实现。操作允许用户自定义编码在分组数据集上来更新用户定义的状态。

## 不支持的操作

- 多个数据流的聚合
- 限制以及获取前N行
- 去重操作
- 排序只能在完全模式聚合下
- 少量的流式外连接不支持


## 启动数据流查询

一旦你定义了最终的结果数据集，那么剩下的就是启动流式计算程序。你需要指定以下一个或者多个接口：

- sink
- Output mode
- Trigger interval
- Checkpoint location


输出模式：

- 追加模式（默认）：只支持添加到结果集的数据不会再变化。
- 全部：支持聚合
- 更新：

## 管理流式查询

StreamingQuery对象可以用来监控管理查询；你可以在一个SparkSession中启动任意数量的查询。他们共享集群资源。可以sparkSession.streams() 得到StreamingQueryManager来管理当前活动的查询。

## 监控流式查询

可以通过metrics来监控，也可以通过编程的方式访问；

# 持续处理 Continuous Processing

【实验性】
持续处理是一个新的实验性的流式处理模式在spark2.3引入，允许低延迟（1ms）端到端至少一次的容错保证。和默认的微批处理引擎相比，可以达到精确一次的保证，而且最好的延迟在100ms之内。对于大多数据查询，你可以选择哪个模式执行而减少逻辑的修改。

运行一个query在continuous processing模式下，你需要指定continuous trigger在指定检查点间隔。

1秒间隔的检查点意味着持续处理引擎会


## 告警（Caveats）

- 持续的处理引擎会生成多个运行的作业持续从数据源读数据，处理，持续写入目标。查询生成的作业数依赖于查询可以从源并发读取多少个分区。因此，在开始处理查询之前，你要确保在集群中有足够的Core。例如：如果从kafka读10个分区，那么集群必须要有10个Core来进行查询。
- 停止一个持续的数据流可能会导致任务的中断告警，可以安全忽略
- 失败的任务无法自动重试。任何的失败会导致查询停止，需要从检查点手工重启。









































